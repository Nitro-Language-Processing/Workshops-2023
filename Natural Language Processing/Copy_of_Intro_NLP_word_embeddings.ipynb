{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Word embeddings"
      ],
      "metadata": {
        "id": "RWD-YEKTFZVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resources\n",
        "\n",
        "- Word2vec (Mikolov et al., 2013): https://code.google.com/archive/p/word2vec/\n",
        "- Fasttext: http://www.fasttext.cc/ (+sub-word information, +multilingual)\n",
        "- Glove (Pennington, Socher, Manning, 2014): http://nlp.stanford.edu/projects/glove/\n",
        "\n",
        "- Multilingual embeddings trained on Wikipedia: https://github.com/facebookresearch/MUSE\n",
        "\n",
        "\n",
        "\n",
        "Gensim documentation: https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec\n",
        "\n",
        "Embeddings visualizer: https://projector.tensorflow.org/\n"
      ],
      "metadata": {
        "id": "0Oi2DL5bUFWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n"
      ],
      "metadata": {
        "id": "gvax3VPDoiFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cS7UF5qBZ9qR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b251596b-04eb-43ae-cc69-bd6837494600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
          ]
        }
      ],
      "source": [
        "# Show all available models in gensim-data\n",
        "import gensim.downloader\n",
        "print(list(gensim.downloader.info()['models'].keys()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = gensim.downloader.load('fasttext-wiki-news-subwords-300') # Note: maybe try ones with fewer dimensions if you want them do be downloaded more quickly"
      ],
      "metadata": {
        "id": "NMZ9on80pA4w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88be596f-bb60-4db1-c2bc-784dabc5eb78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=================================================-] 99.6% 955.0/958.4MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(embeddings.index2word)) # ~1mil words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsZXM3PmpGk5",
        "outputId": "5408701b-b5ff-4a67-aece-9bce21f8b692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.get_vector('cat')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqB8mnkVg4ww",
        "outputId": "03ba0de1-61be-4729-b06d-cf2e13c0f720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4.7426e-02, -4.2203e-02,  2.8491e-02, -4.4481e-02, -2.6467e-02,\n",
              "        3.3557e-02,  1.7173e-01, -1.4773e-01,  7.1133e-02,  3.8385e-02,\n",
              "       -7.9921e-02, -1.3236e-03,  1.6185e-01, -1.6389e-01, -6.5456e-02,\n",
              "        2.7030e-02,  1.2193e-01, -7.1632e-02,  7.9642e-02, -1.4602e-01,\n",
              "        1.0369e-02, -1.0468e-01,  3.6734e-02,  7.9116e-02,  1.8241e-01,\n",
              "       -2.4902e-03,  1.3818e-02,  1.2378e-01,  1.7348e-04,  1.6646e-02,\n",
              "       -1.3513e-02, -7.5532e-02,  1.0060e-01,  7.1226e-02, -2.7468e-02,\n",
              "       -7.8517e-02,  3.3769e-02, -1.6082e-01, -2.2747e-02, -1.3238e-01,\n",
              "        1.1198e-02, -1.2838e-01, -5.8910e-02, -5.1399e-02,  3.9177e-02,\n",
              "        5.8243e-02,  2.2071e-02,  7.1876e-02,  2.8166e-02, -1.8918e-02,\n",
              "        3.4445e-02,  1.5664e-01,  6.9836e-02, -2.0858e-01,  2.4413e-03,\n",
              "       -8.9110e-02, -6.0705e-02,  6.5106e-02, -8.3036e-02,  1.7491e-02,\n",
              "       -3.4527e-02, -2.5026e-01,  1.8777e-01, -3.6235e-02,  1.2452e-01,\n",
              "        2.4356e-02, -4.4517e-03,  5.5572e-02, -8.6161e-03, -1.6188e-01,\n",
              "        1.8468e-02,  3.3442e-02,  6.2601e-02, -6.4390e-02,  4.9347e-02,\n",
              "        4.0229e-02, -1.0841e-01, -7.1824e-02,  2.8520e-03, -2.3045e-02,\n",
              "        4.4209e-02, -7.7235e-02,  1.1654e-01,  7.0451e-02,  6.8801e-02,\n",
              "       -1.5605e-01, -6.6329e-02,  2.5411e-02,  1.8099e-01,  1.8025e-02,\n",
              "       -1.3115e-02,  3.9657e-02, -1.4402e-01, -3.2715e-02,  1.5651e-01,\n",
              "        1.9193e-01,  5.5521e-02,  8.3402e-02,  3.1470e-02,  3.8014e-02,\n",
              "        7.7720e-02,  2.3055e-02,  1.3798e-02,  2.9269e-02, -4.0150e-02,\n",
              "       -2.2689e-01, -1.0853e-01,  4.8246e-02, -1.1478e-02, -3.3596e-02,\n",
              "       -2.2763e-02,  4.4926e-02,  4.3869e-02, -2.2687e-02, -5.7857e-02,\n",
              "       -9.0331e-02,  4.0408e-02,  2.3637e-02, -4.9092e-02,  7.6129e-02,\n",
              "       -5.6087e-02,  1.3707e-01,  6.7951e-03, -9.9982e-02,  1.1920e-01,\n",
              "        1.2967e-01, -1.1956e-02, -1.6192e-01, -1.1653e-01,  8.6265e-02,\n",
              "       -4.6044e-02, -4.1525e-02, -5.4869e-02,  1.3872e-01, -5.8306e-02,\n",
              "       -1.0037e-03, -4.7553e-02,  9.7019e-02,  6.6086e-02, -4.2082e-02,\n",
              "       -1.4740e-02,  7.6810e-02,  6.4693e-02, -5.0720e-02, -3.4010e-02,\n",
              "       -1.8386e-01,  6.8373e-03, -8.1774e-02, -2.5614e-02, -8.7315e-02,\n",
              "       -2.2828e-02,  8.1626e-02,  2.9836e-02, -2.3802e-02, -7.9236e-02,\n",
              "       -6.1760e-02, -7.5404e-02, -8.7516e-02, -1.0102e-01, -3.1656e-02,\n",
              "       -2.2954e-02,  4.2454e-02, -5.7946e-02,  9.3254e-02, -6.7006e-04,\n",
              "       -4.3120e-02,  2.5232e-03,  3.4711e-02, -9.8615e-02, -6.0120e-02,\n",
              "       -6.7252e-02,  1.1061e-01, -1.2473e-01,  1.0016e-01, -6.0412e-02,\n",
              "        1.3936e-01, -3.7146e-03,  4.3347e-02,  2.1273e-02,  4.6771e-03,\n",
              "        9.4169e-02, -1.5631e-01,  2.0714e-02, -1.3038e-01,  1.0644e-02,\n",
              "       -1.0240e-01,  1.8860e-02,  1.4838e-01, -2.6096e-02, -1.9504e-01,\n",
              "       -1.0817e-01,  4.9979e-02, -3.9784e-02, -7.4161e-02, -7.7483e-03,\n",
              "        1.3766e-01, -4.5317e-02,  1.3089e-01, -1.0939e-02,  6.2601e-02,\n",
              "       -1.9160e-01,  1.5974e-01, -2.2695e-02, -3.6044e-02,  8.5172e-03,\n",
              "       -5.9913e-02,  2.5738e-02, -1.4296e-02, -1.0799e-01, -8.0345e-02,\n",
              "        2.3639e-01, -7.1429e-02, -3.1922e-02, -4.9206e-02, -1.4092e-02,\n",
              "        5.2687e-02,  4.9890e-02, -8.2620e-02,  7.4192e-02,  4.9126e-02,\n",
              "        9.6644e-03,  6.2958e-02, -4.6600e-02,  1.3632e-01,  3.2190e-02,\n",
              "        1.1145e-01, -6.8493e-02,  1.1836e-01,  9.7115e-02, -5.9462e-03,\n",
              "       -3.9682e-02, -1.1015e-01, -8.3191e-02, -6.9569e-02,  1.7800e-02,\n",
              "       -7.3179e-02,  1.4049e-01,  3.6892e-03, -5.4191e-02, -2.3150e-02,\n",
              "        8.9252e-02, -5.5929e-04,  2.0313e-02, -1.3092e-02,  3.9476e-02,\n",
              "        2.0953e-01,  4.4137e-02,  5.8339e-02, -8.8616e-02, -7.2534e-02,\n",
              "        5.6144e-04, -1.2490e-01, -5.5088e-02,  8.0493e-02,  7.3815e-02,\n",
              "       -7.2982e-02,  7.6267e-02, -6.0362e-02,  4.7157e-02,  1.1720e-01,\n",
              "       -3.5231e-02, -8.4633e-02,  8.5297e-02, -8.7477e-02, -2.9710e-02,\n",
              "       -4.2450e-02, -8.1470e-03,  1.4035e-02,  9.5844e-02,  2.5391e-02,\n",
              "       -1.6090e-01,  1.4980e-01, -1.5577e-01, -5.9259e-02,  6.8384e-02,\n",
              "       -2.2155e-02,  3.9042e-02, -1.1343e-01,  8.8454e-03, -1.2065e-02,\n",
              "        1.2282e-01,  1.6502e-02,  1.0734e-01, -2.6010e-02, -2.9067e-02,\n",
              "        7.2578e-02, -6.0300e-02, -5.0048e-02, -7.1067e-04,  2.6096e-02,\n",
              "        3.7569e-02,  2.2775e-02, -1.8111e-01, -1.2339e-01,  3.6638e-02,\n",
              "        8.9385e-02,  3.8261e-02,  1.7148e-01,  1.4416e-02,  1.3847e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.most_similar('cat')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMCBJgyJDYQi",
        "outputId": "f150a4fc-9d1f-4c93-8eb5-678b27e9f8e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('cats', 0.8368596434593201),\n",
              " ('housecat', 0.7674711346626282),\n",
              " ('-cat', 0.7602992057800293),\n",
              " ('dog', 0.7502298355102539),\n",
              " ('kitten', 0.7480818033218384),\n",
              " ('feline', 0.7353992462158203),\n",
              " ('super-cat', 0.7305205464363098),\n",
              " ('supercat', 0.7163283824920654),\n",
              " ('pet', 0.7090284824371338),\n",
              " ('moggy', 0.7057286500930786)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cosine_similarity(\n",
        "    embeddings.get_vector('cat').reshape(1,-1),\n",
        "    embeddings.get_vector('kitten').reshape(1,-1)\n",
        "    )[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQzhs_7sg-Cn",
        "outputId": "307e333b-9753-4eaf-855f-29e53b77e777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7480817"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.similarity('cat', 'kitten')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urAcLbyz7SZ4",
        "outputId": "eb46b53e-442b-4610-a272-e90d903f210a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.74808174"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Synonymy vs relatedness"
      ],
      "metadata": {
        "id": "P7XVQu1qCnm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.similarity('uncle', 'sister')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCtTxVah7ZZi",
        "outputId": "c7a90c41-db9d-43fc-afe6-391c2d57ff16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7174434"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.similarity('sibling', 'sister')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMre1u9tiS6o",
        "outputId": "47647907-dce9-475f-c704-0d926899b61a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.76012087"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.similarity('good', 'bad')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecnLiWeqicRF",
        "outputId": "ab723f8e-cc2c-46a1-8ea6-acdb574d7823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8503089"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.similarity('Monday', 'Sunday')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--V6s53A7vDg",
        "outputId": "a23ec6b0-2d80-40f6-dda9-e7e33ad8b0f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.85126"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalization & correcting typos"
      ],
      "metadata": {
        "id": "0_KmVoL9pbhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.most_similar(\"defenitly\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV1jF15JpeMD",
        "outputId": "6e7a5bde-3d64-45b7-872b-305e62961677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('defenitely', 0.8840630650520325),\n",
              " ('defenetly', 0.845188558101654),\n",
              " ('defently', 0.8433688282966614),\n",
              " ('definitly', 0.770545482635498),\n",
              " ('definetly', 0.7526832222938538),\n",
              " ('politly', 0.7457025051116943),\n",
              " ('defnitely', 0.7323918342590332),\n",
              " ('probebly', 0.7254762649536133),\n",
              " ('definatly', 0.7249115109443665),\n",
              " ('usuallly', 0.7225544452667236)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.most_similar(\"hiii\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hxcw4ASLpyz6",
        "outputId": "7bb5aeca-c09b-4f14-a769-3797fd081f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('hiiii', 0.9428294897079468),\n",
              " ('Hiii', 0.8571420311927795),\n",
              " ('Hiiii', 0.8538976311683655),\n",
              " ('hii', 0.7178279161453247),\n",
              " ('iiii', 0.7104865908622742),\n",
              " ('plzzz', 0.6919779777526855),\n",
              " ('plzzzz', 0.685299813747406),\n",
              " ('hhh', 0.6836094260215759),\n",
              " ('wazzup', 0.6829248070716858),\n",
              " ('plzz', 0.6775454878807068)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Word analogies"
      ],
      "metadata": {
        "id": "L0N_xItsCruF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# king - man + woman\n",
        "embeddings.most_similar_cosmul(positive=['king', 'woman'], negative=['man'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mn_AXBVXSil",
        "outputId": "fcd91de5-2534-4281-d5b5-e5ae385a6b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.9390855431556702),\n",
              " ('queen-mother', 0.9078598618507385),\n",
              " ('king-', 0.8828967213630676),\n",
              " ('queen-consort', 0.882541835308075),\n",
              " ('child-king', 0.8680858016014099),\n",
              " ('monarch', 0.8670082688331604),\n",
              " ('ex-queen', 0.8654636740684509),\n",
              " ('princess', 0.8628991842269897),\n",
              " ('queen-', 0.8613532781600952),\n",
              " ('boy-king', 0.8604660630226135)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rome - Italy + France\n",
        "embeddings.most_similar_cosmul(positive=['Rome', 'France'], negative=['Italy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2ChBzS5T-8I",
        "outputId": "57b6b3e9-6542-487d-c98b-67a865bfa44f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Paris', 0.9433913826942444),\n",
              " ('Meaux', 0.8968006372451782),\n",
              " ('Avignon', 0.8785353302955627),\n",
              " ('Saint-Denis', 0.8744451403617859),\n",
              " ('Rouen', 0.8729321956634521),\n",
              " ('Lyon', 0.8724958300590515),\n",
              " ('Louville', 0.8714753985404968),\n",
              " ('Toulouse', 0.8713098168373108),\n",
              " ('Beauvais', 0.8704253435134888),\n",
              " ('Blois', 0.8698782920837402)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# programmer - man + woman\n",
        "embeddings.most_similar_cosmul(positive=['programmer', 'woman'], negative=['man'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAHu5N2Nhn-q",
        "outputId": "9228b417-62b2-4251-941a-9468bdc11419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('non-programmer', 0.864444375038147),\n",
              " ('programmers', 0.857123851776123),\n",
              " ('Programmer', 0.8313319683074951),\n",
              " ('non-programmers', 0.8269447088241577),\n",
              " ('writer', 0.8260436058044434),\n",
              " ('coder', 0.8254762887954712),\n",
              " ('programer', 0.8239933848381042),\n",
              " ('nonprogrammers', 0.8238459229469299),\n",
              " ('web-designer', 0.8198288679122925),\n",
              " ('researcher', 0.8139449954032898)]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training embeddings"
      ],
      "metadata": {
        "id": "jD7s90_asUVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_embeddings = gensim.models.Word2Vec(sentences=None, corpus_file=None,\n",
        "                                size=100, alpha=0.025, window=5, min_count=5,\n",
        "                                max_vocab_size=None, sample=0.001, seed=1, workers=3, min_alpha=0.0001, sg=0, hs=0,\n",
        "                                negative=5, ns_exponent=0.75, cbow_mean=1, null_word=0, trim_rule=None,\n",
        "                                sorted_vocab=1, batch_words=10000, compute_loss=False, callbacks=(),\n",
        "                                max_final_vocab=None)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWnZgfmrsVzP",
        "outputId": "9b6b7600-3b9f-4de2-92b8-58dd502da8ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.word2vec.Word2Vec at 0x7f1c0dc88fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Texts as embedding sequences\n",
        "\n",
        "Moving on from one-hot-encodings and frequency vectors"
      ],
      "metadata": {
        "id": "OS8tQr04TnGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        " 'This is the first document.',\n",
        " 'This document is the second document.',\n",
        " 'And this is the third one.',\n",
        " 'Is this the first document?',\n",
        " '@user This one is a tweet #meta ;)'\n",
        "]"
      ],
      "metadata": {
        "id": "aemhy6E6To4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First tokenize the text... see previous notebook!\n",
        "# Note: do we still need lemmatization if we use embeddings? Debatable.\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "corpus_tokenized = [nltk.word_tokenize(s) for s in corpus]\n",
        "print(corpus_tokenized)"
      ],
      "metadata": {
        "id": "CS5QNBU_WABC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_encoded = []\n",
        "for sent in corpus_tokenized:\n",
        "  sentence_encoded = []\n",
        "  for word in sent:\n",
        "    sentence_encoded.append(embeddings[word])\n",
        "  corpus_encoded.append(sentence_encoded)\n",
        "print(corpus_encoded) # Ready for machine learning!"
      ],
      "metadata": {
        "id": "p2N4Gmq4V8ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## False friends"
      ],
      "metadata": {
        "id": "ZQyiNUwwbeWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/arrival/vectors/wiki.multi.en.vec # English embeddings, prealigned\n",
        "!wget https://dl.fbaipublicfiles.com/arrival/vectors/wiki.multi.es.vec # Spanish embeddings, prealigned"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3N9PtT2bgG1",
        "outputId": "908863d8-c4e6-4174-8a81-60d7a419d3d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-19 19:52:56--  https://dl.fbaipublicfiles.com/arrival/vectors/wiki.multi.en.vec\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 628614720 (599M) [text/plain]\n",
            "Saving to: ‘wiki.multi.en.vec’\n",
            "\n",
            "wiki.multi.en.vec   100%[===================>] 599.49M  66.3MB/s    in 9.8s    \n",
            "\n",
            "2023-03-19 19:53:06 (61.1 MB/s) - ‘wiki.multi.en.vec’ saved [628614720/628614720]\n",
            "\n",
            "--2023-03-19 19:53:06--  https://dl.fbaipublicfiles.com/arrival/vectors/wiki.multi.es.vec\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 628826336 (600M) [text/plain]\n",
            "Saving to: ‘wiki.multi.es.vec’\n",
            "\n",
            "wiki.multi.es.vec   100%[===================>] 599.70M  63.9MB/s    in 9.6s    \n",
            "\n",
            "2023-03-19 19:53:16 (62.6 MB/s) - ‘wiki.multi.es.vec’ saved [628826336/628826336]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "en_model = KeyedVectors.load_word2vec_format('wiki.multi.en.vec')  # Watch out for your RAM...\n",
        "es_model = KeyedVectors.load_word2vec_format('wiki.multi.es.vec')\n"
      ],
      "metadata": {
        "id": "EYwwny90chkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embarrassed_vec = en_model.get_vector(\"embarassed\")\n",
        "pregnant_vec = en_model.get_vector(\"pregnant\")\n",
        "embarazada_vec = es_model.get_vector(\"embarazada\")"
      ],
      "metadata": {
        "id": "WPU54CMudDoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "similarity_matrix = cosine_similarity([embarrassed_vec, pregnant_vec, embarazada_vec])\n",
        "\n",
        "words = (\"embarrassed\", \"pregnant\", \"embarazada\")\n",
        "print(\"%27s %15s %15s\" % words)\n",
        "for i, row in enumerate(similarity_matrix):\n",
        "  print(\"%15s %.13f %.13f %.13f\" % (words[i], *row))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ag4xannLddR-",
        "outputId": "643957e4-fd41-4834-f459-ed73d2e53334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                embarrassed        pregnant      embarazada\n",
            "    embarrassed 0.9999999403954 0.2995810210705 0.3134102821350\n",
            "       pregnant 0.2995810210705 1.0000000000000 0.8302524089813\n",
            "     embarazada 0.3134102821350 0.8302524089813 1.0000000000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es_model.similar_by_vector(embarrassed_vec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o14wPO0ugqMa",
        "outputId": "14fafba2-2cfa-468b-d8af-b9054bd10e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('parecerme', 0.6807215213775635),\n",
              " ('insultarme', 0.6778432726860046),\n",
              " ('sinceramente', 0.675748884677887),\n",
              " ('discúlpame', 0.6600538492202759),\n",
              " ('equivocarme', 0.6517462730407715),\n",
              " ('digo', 0.6503289937973022),\n",
              " ('diciéndome', 0.6467952132225037),\n",
              " ('disculpo', 0.6451693773269653),\n",
              " ('disculparme', 0.6407719850540161),\n",
              " ('ridículo', 0.6402308940887451)]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contextual embeddings and language models... to be continued :)"
      ],
      "metadata": {
        "id": "q3XYBoeTTpVM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extra links**:\n",
        "\n",
        "Using contextual embeddings for detecting pejorative words on Twitter https://aclanthology.org/2021.findings-emnlp.296.pdf\n",
        "\n",
        "\n",
        "> \"This workshop is *trash*!\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "and a lexicon of pejorative words (including Romanian): https://nlp.unibuc.ro/resources.html#pejor"
      ],
      "metadata": {
        "id": "MN32rmQ_hGyl"
      }
    }
  ]
}